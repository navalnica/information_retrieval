{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f0f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5b548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438e336b",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3270723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_path(title):\n",
    "#     fp = filemap.query('filename == @title.lower().strip()')['relpath'].iloc[0]\n",
    "    fp = filemap.query('filename == @title.lower().strip()')['path'].iloc[0]\n",
    "#     fp = os.path.join(articles_dp, fp)\n",
    "    return fp\n",
    "\n",
    "def get_article_text(fp):\n",
    "    with open(fp) as fin: text = fin.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d633b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_title(title: pd.Series):\n",
    "    title = title.str.lower().str.strip()\n",
    "    title = title.str.replace(r'([^\\w\\s])|_|-', '_', regex=True)\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98084695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sets_stats(arr1, arr2):\n",
    "    print(f'init shapes: {len(arr1), len(arr2)}')\n",
    "    s1 = set(arr1)\n",
    "    s2 = set(arr2)\n",
    "    print(f'unique elements: {len(s1), len(s2)}')\n",
    "    print(f's1 & s2: {len(s1 & s2)}')\n",
    "    print(f's1 ^ s2: {len(s1 ^ s2)}')\n",
    "    print(f's1 - s2: {len(s1 - s2)}')\n",
    "    print(f's2 - s1: {len(s2 - s1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8296c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d59633f6",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f5d6604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223619, 3)\n"
     ]
    }
   ],
   "source": [
    "data_root_dp = '/media/rtn/Windows 10/work/univier/wiki_extract/wiki_parsed'\n",
    "# articles_dp = os.path.join(data_root_dp, 'articles')\n",
    "# filemap = pd.read_csv(os.path.join(data_root_dp, 'filemap.csv'))\n",
    "articles_dp = data_root_dp\n",
    "filemap = pd.read_csv(os.path.join(data_root_dp, 'filepaths.csv'))\n",
    "print(filemap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d92aa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Poetry is a type of art form and a type of literature. Poetry uses the qualities of words, in different ways, to be artistic. Poetry can be as short as a few words, or as long as a book. A poem as short as one line is called a monostich. A poem that is as long as a book is an epic. There are many \"poetic forms\" (forms of poetry). Some of forms are: Sonnet, Haiku, Ballad, Stev, Prose poem, Ode, Free verse, Blank verse, thematic, limerick and nursery rhymes. Poetry can be used to describe (comparing, talking about, or expressing emotion) many things. It can make sense or be nonsense, it can rhyme or not. It can have many shapes and sizes; it can be serious or funny. \"To say something poetically\" means to give information in an artistic way. A more modern approach is digital poetry. Computers and webtechnology is used to express poetry and make it interactive. So called interdisciplinary poetry (wich means combination of different forms of poetry) are made possible by linking the poetic texts with audio, video or web-animation (e.g. with CSS) or among themselves via hyperlinks. Modern artists use digital poetry to not only express artistic intention, but also to design a layout around their texts. An example for this use of interdisciplinary art, which combines abstract text and abstract visuals is the german project \"Schwarzer Flamingo\". It uses digital poetry to collect pieces of written art but also to give different artists a plattform. So some projects of digital art can be described as a form of an artwork as well as an exhibition.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_article_text(get_article_path('poetry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeb69b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7681e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animals that have shells and live in water</td>\n",
       "      <td>shell__zoology_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how many different types of scorpions are there</td>\n",
       "      <td>scorpion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>describe the structure of a scientific name fo...</td>\n",
       "      <td>binomial_nomenclature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query                  title\n",
       "0         animals that have shells and live in water        shell__zoology_\n",
       "1    how many different types of scorpions are there               scorpion\n",
       "2  describe the structure of a scientific name fo...  binomial_nomenclature"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = pd.read_csv('data/queries.tsv', sep='\\t', header=None)\n",
    "labels_test.columns = ['query', 'title']\n",
    "labels_test['title'] = process_title(labels_test['title'])\n",
    "\n",
    "print(labels_test.shape)\n",
    "labels_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4110bee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>where does the most metabolic activity in the ...</td>\n",
       "      <td>cytoplasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what kind of dog played in turner and hooch</td>\n",
       "      <td>dogue_de_bordeaux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when is there gonna be an eclipse 2017</td>\n",
       "      <td>solar_eclipse_of_august_21__2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  where does the most metabolic activity in the ...   \n",
       "1        what kind of dog played in turner and hooch   \n",
       "2             when is there gonna be an eclipse 2017   \n",
       "\n",
       "                              title  \n",
       "0                         cytoplasm  \n",
       "1                 dogue_de_bordeaux  \n",
       "2  solar_eclipse_of_august_21__2017  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train_raw = pd.read_csv('data/train.tsv', sep='\\t', header=None)\n",
    "labels_train_raw.columns = ['query', 'title']\n",
    "labels_train_raw['title'] = process_title(labels_train_raw['title'])\n",
    "\n",
    "print(labels_train_raw.shape)\n",
    "labels_train_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c1ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72da595",
   "metadata": {},
   "outputs": [],
   "source": [
    "filemap['article_id'] = list(range(filemap.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164c9b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filename                                                belarus\n",
       "path          /media/rtn/Windows 10/work/univier/wiki_extrac...\n",
       "html_path     /media/rtn/Windows 10/work/univier/wiki_extrac...\n",
       "article_id                                                25864\n",
       "Name: 25864, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title2id = filemap.set_index('filename')['article_id'].to_dict()\n",
    "filemap.iloc[title2id['belarus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca99bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cec1bf9",
   "metadata": {},
   "source": [
    "### filter train, test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5acfc115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init shapes: (223619, 50000)\n",
      "unique elements: (223619, 16731)\n",
      "s1 & s2: 15430\n",
      "s1 ^ s2: 209490\n",
      "s1 - s2: 208189\n",
      "s2 - s1: 1301\n"
     ]
    }
   ],
   "source": [
    "two_sets_stats(filemap['filename'], labels_train_raw['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b172bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init shapes: (223619, 200)\n",
      "unique elements: (223619, 142)\n",
      "s1 & s2: 137\n",
      "s1 ^ s2: 223487\n",
      "s1 - s2: 223482\n",
      "s2 - s1: 5\n"
     ]
    }
   ],
   "source": [
    "two_sets_stats(filemap['filename'], labels_test['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a037b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45260\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "labels_train_raw = labels_train_raw[labels_train_raw['title'].isin(filemap['filename'])]\n",
    "labels_test = labels_test[labels_test['title'].isin(filemap['filename'])]\n",
    "print(labels_train_raw.shape[0])\n",
    "print(labels_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcfcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb954d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09f329d8",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad5bba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'using device: {device}')\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import sentence_transformers as st\n",
    "import sentence_transformers.losses\n",
    "from sentence_transformers.datasets import NoDuplicatesDataLoader\n",
    "from sentence_transformers.readers import InputExample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e39c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a8143f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38471, 2)\n",
      "(6789, 2)\n"
     ]
    }
   ],
   "source": [
    "labels_train, labels_val = train_test_split(labels_train_raw, random_state=12, test_size=0.15, shuffle=True)\n",
    "print(labels_train.shape)\n",
    "print(labels_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c0256e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38886</th>\n",
       "      <td>a sea route through the arctic ocean in canada...</td>\n",
       "      <td>northwest_passage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15973</th>\n",
       "      <td>who plays angie on the george lopez show</td>\n",
       "      <td>constance_marie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46486</th>\n",
       "      <td>who plays queen cersei on game of thrones</td>\n",
       "      <td>lena_headey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7715</th>\n",
       "      <td>who plays the dolphin in the spongebob movie</td>\n",
       "      <td>the_spongebob_movie__sponge_out_of_water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39805</th>\n",
       "      <td>the mask of the red death by edgar allan poe</td>\n",
       "      <td>the_masque_of_the_red_death</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   query  \\\n",
       "38886  a sea route through the arctic ocean in canada...   \n",
       "15973           who plays angie on the george lopez show   \n",
       "46486          who plays queen cersei on game of thrones   \n",
       "7715        who plays the dolphin in the spongebob movie   \n",
       "39805       the mask of the red death by edgar allan poe   \n",
       "\n",
       "                                          title  \n",
       "38886                         northwest_passage  \n",
       "15973                           constance_marie  \n",
       "46486                               lena_headey  \n",
       "7715   the_spongebob_movie__sponge_out_of_water  \n",
       "39805               the_masque_of_the_red_death  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8482bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c03795",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiQAInputExample(InputExample):\n",
    "    def __init__(self, guid: str = '', texts: List[str] = None,  label: Union[int, float] = 0, article_id: int = None):\n",
    "        self.article_id = article_id\n",
    "        super().__init__(guid, texts, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "798a136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiQADataset(Dataset):\n",
    "    def __init__(self, examples: pd.DataFrame, title2id):\n",
    "        self.examples = examples\n",
    "        self.title2id = title2id\n",
    "        assert isinstance(examples, pd.DataFrame)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        assert 0 <= ix < len(self)\n",
    "        query, article_title = self.examples.iloc[ix][['query', 'title']]\n",
    "        article = get_article_text(get_article_path(article_title))\n",
    "        example = WikiQAInputExample(texts=[query, article], label=1, article_id=self.title2id[article_title])\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d65e8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNoDuplicatesDataLoader:\n",
    "\n",
    "    def __init__(self, dataset: WikiQADataset, batch_size):\n",
    "        \"\"\"\n",
    "        A special data loader to be used with MultipleNegativesRankingLoss.\n",
    "        The data loader ensures that there are no duplicate sentences within the same batch\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = None\n",
    "        self.dataset = dataset\n",
    "        self.data_pointer = 0\n",
    "        self.index_order = list(range(len(dataset)))\n",
    "        random.shuffle(self.index_order)  # shuffle index inplace before the first iteration\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.__len__()):\n",
    "            batch = []\n",
    "            texts_in_batch = set()\n",
    "\n",
    "            while len(batch) < self.batch_size:\n",
    "                ix = self.index_order[self.data_pointer]\n",
    "                example = self.dataset[ix]\n",
    "\n",
    "                valid_example = True\n",
    "                for text in example.texts:\n",
    "                    if text.strip().lower() in texts_in_batch:\n",
    "                        valid_example = False\n",
    "                        break\n",
    "\n",
    "                if valid_example:\n",
    "                    batch.append(example)\n",
    "                    for text in example.texts:\n",
    "                        texts_in_batch.add(text.strip().lower())\n",
    "\n",
    "                self.data_pointer += 1\n",
    "                if self.data_pointer >= len(self.dataset):\n",
    "                    self.data_pointer = 0\n",
    "                    random.shuffle(self.index_order)  # reshuffle index order\n",
    "\n",
    "            yield self.collate_fn(batch) if self.collate_fn is not None else batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.floor(len(self.dataset) / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5a679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c577cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WikiQADataset(labels_train, title2id=title2id)\n",
    "# val_dataset = WikiQADataset(labels_val, title2id=title2id)\n",
    "# print(f'train, val lenghts: {len(train_dataset), len(val_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae16bce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who plays the dolphin in the spongebob movie',\n",
       " 'The SpongeBob Movie: Sponge Out of Water is a 2015 3D animated/live action superhero comedy movie based on Nickelodeon\\'s SpongeBob SquarePants television series. It is preceded by The SpongeBob SquarePants Movie. It was produced by Nickelodeon Movies and Paramount Animation, and was distributed by Paramount Pictures. It was released theatrically on February 6, 2015. The movie released February 6, 2015 on HD Digital. It was nominated in the 2015 Kids\\' Choice Awards for \"Favorite Animated Movie\", but lost to Disney\\'s 54th feature film Big Hero 6. A diabolical pirate named Burger Beard above the sea steals the secret Krabby Patty formula. SpongeBob, Patrick, Mr. Krabs, Sandy and Squidward must team up with Plankton in order to get it back unbounce. Tom Kenny as SpongeBob SquarePants/Invincibubble and Gary the Snail Bill Fagerbakke as Patrick Star/Mr. Superawesomeness Mr. Lawrence as Plankton/Plank-Ton Clancy Brown as Mr. Krabs/Sir Pinch-A-Lot Rodger Bumpass as Squidward Tentacles/Sour Note Carolyn Lawrence as Sandy Cheeks/The Rodent Antonio Banderas as Burger-Beard the Pirate Paul Tibbitt as Kyle the Seagull Nolan North as Pigeon Cabbie Jill Talley as Karen The seagullsâ€™ voices are provided by Alan Oppenheimer, Tim Conway, Harry Shearer, David L. Lander, Tress MacNeille, Billy West, Joe Alaskey, Rob Paulsen, Eddie Deezen, Nancy Cartwright, Dan Castellaneta, Maurice LaMarche, Lauren Tom, Richard Steven Horvitz, Phil LaMarr, David Herman, John DiMaggio, Cree Summer, April Stewart, Nolan North, Danica McKellar, Fred Savage, and Eric Bauza.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[3].texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb84479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c3f15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: has max_seq_length: 128\n",
    "model = st.SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ae6b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = st.losses.MultipleNegativesRankingLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c787fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e403a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_batch_size: 32\n",
      "num_epochs: 2\n",
      "Warmup-steps: 962\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 32\n",
    "num_epochs = 2\n",
    "warmup_steps = math.ceil(len(train_dl) * num_epochs * 0.1)\n",
    "model_save_path = '/media/rtn/data/fajly2/checkpoints/bert'\n",
    "\n",
    "train_dl = CustomNoDuplicatesDataLoader(train_dataset, batch_size=train_batch_size)\n",
    "\n",
    "print(f'train_batch_size: {train_batch_size}')\n",
    "print(f\"num_epochs: {num_epochs}\")\n",
    "print(f\"Warmup-steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9d39458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2d6c2bab0c4b598314fc9666c52ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581b7e2f88eb45438b95dd91f0f840ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29448/99831414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_objectives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     evaluator=dev_evaluator,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     evaluation_steps=int(len(train_dl)*0.1),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/info/venv/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    692\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0muse_amp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                         \u001b[0mscale_before_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/info/venv/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/info/venv/lib/python3.9/site-packages/sentence_transformers/losses/MultipleNegativesRankingLoss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Example a[i] should match with b[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dl, train_loss)],\n",
    "#     evaluator=dev_evaluator,\n",
    "    epochs=num_epochs,\n",
    "#     evaluation_steps=int(len(train_dl)*0.1),\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    "    use_amp=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bca3aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779f789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194052d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a3bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db528b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d56c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d52f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
